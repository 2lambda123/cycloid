{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.80318667, -8.06230683, -8.08928983, -7.73324357, -8.03371159,\n",
       "       -8.14997983, -8.31886401, -7.84531503, -7.75299181, -7.98508002])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import sin, cos, arctan2 as atan2, log, pi\n",
    "Np = 10\n",
    "Nl = 8\n",
    "\n",
    "X = np.zeros((3, Np))\n",
    "L = np.zeros((5, Nl, Np))\n",
    "L[:2] = np.random.randn(2, Nl, Np)\n",
    "L[2] = 1e6\n",
    "L[4] = 1e6\n",
    "\n",
    "def pf_update(X, L, l_px, r):\n",
    "    # Do a particle filter update: first, evaluate likelihood of every landmark for every particle\n",
    "    # X.shape is [3, NumParticles] (x, y, theta)\n",
    "    # L.shape is [5, NumLandmarks, NumParticles] (x, y, p11, p12, p22)\n",
    "    p_x = X[0]\n",
    "    p_y = X[1]\n",
    "    theta = X[2]\n",
    "    l_x = L[0]\n",
    "    l_y = L[1]\n",
    "    p11 = L[2]\n",
    "    p12 = L[3]\n",
    "    p22 = L[4]\n",
    "    \n",
    "    k0 = cos(theta)\n",
    "    k1 = l_y - p_y\n",
    "    k2 = k0*k1\n",
    "    k3 = sin(theta)\n",
    "    k4 = l_x - p_x\n",
    "    k5 = k3*k4\n",
    "    k6 = k0*k4 + k1*k3\n",
    "    k7 = l_px - atan2(k2 - k5, k6)\n",
    "    k8 = -k2 + k5\n",
    "    k9 = k0*k6 + k3*k8\n",
    "    k10 = k6**2 + k8**2\n",
    "    k11 = k10**(-2)\n",
    "    k12 = k0*k8 - k3*k6\n",
    "    k13 = k11*k12*(k12*p11 + k9*p12) + k11*k9*(k12*p12 + k9*p22) + r\n",
    "    k14 = 1/k10\n",
    "    \n",
    "    # also compute some handy quantities\n",
    "    LL = -0.5*log(4*pi**2*k13) - k7**2/k13\n",
    "\n",
    "    # get the maximum likelihood\n",
    "    i = np.argmax(LL, axis=0)\n",
    "    j = np.arange(Np)\n",
    "    LL = LL[i, j]\n",
    "    y_k = k7[i, j]\n",
    "    S = k13[i, j]\n",
    "    H1 = k12[i, j]*k14[i, j]\n",
    "    H2 = k14[i, j]*k9[i, j]\n",
    "    p11 = L[2, i, j]\n",
    "    p12 = L[3, i, j]\n",
    "    p22 = L[4, i, j]\n",
    "    \n",
    "    # we should resample based on LL at this step, *then* update the EKFs!\n",
    "    # although actually, we end up doing exactly the same amount of work, so maybe not\n",
    "    # *shrug* ok, let's update EKF and then throw away some particles\n",
    "    \n",
    "    k0 = 1/S\n",
    "    k1 = H2*p12\n",
    "    k2 = k0*(H1*p11 + k1)\n",
    "    k3 = H1*p12\n",
    "    k4 = H2*p22\n",
    "    k5 = k0*(k3 + k4)\n",
    "    k6 = H1*k2 - 1\n",
    "    L[0, i, j] += k2*y_k\n",
    "    L[1, i, j] += k5*y_k\n",
    "    L[2, i, j] = -k1*k2 - k6*p11\n",
    "    L[3, i, j] = -k2*k4 - k6*p12\n",
    "    L[4, i, j] = -k3*k5 - p22*(H2*k5 - 1)\n",
    "    \n",
    "    return LL\n",
    "\n",
    "pf_update(X, L, 0.1, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
